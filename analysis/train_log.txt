Train losses:
epoch 0, global step 10, total step 721440, train lm loss: 5.222499597072601
epoch 0, global step 20, total step 721440, train lm loss: 5.789428919553757
epoch 0, global step 30, total step 721440, train lm loss: 5.8029531121253966
epoch 0, global step 40, total step 721440, train lm loss: 5.902120578289032
epoch 0, global step 50, total step 721440, train lm loss: 5.77754225730896
epoch 0, global step 60, total step 721440, train lm loss: 5.821744167804718
epoch 0, global step 70, total step 721440, train lm loss: 5.629656028747559
epoch 0, global step 80, total step 721440, train lm loss: 5.4005347162485124
epoch 0, global step 90, total step 721440, train lm loss: 5.252670758962632
epoch 0, global step 100, total step 721440, train lm loss: 4.725986182689667
epoch 0, global step 110, total step 721440, train lm loss: 4.297145739197731
epoch 0, global step 120, total step 721440, train lm loss: 4.032460504770279
epoch 0, global step 130, total step 721440, train lm loss: 3.3708786010742187
epoch 0, global step 140, total step 721440, train lm loss: 2.8358907967805864
epoch 0, global step 150, total step 721440, train lm loss: 2.6827646881341933
epoch 0, global step 160, total step 721440, train lm loss: 2.557158926129341
epoch 0, global step 170, total step 721440, train lm loss: 2.4382249236106874
epoch 0, global step 180, total step 721440, train lm loss: 2.411767992377281
epoch 0, global step 190, total step 721440, train lm loss: 2.4027918934822083
epoch 0, global step 200, total step 721440, train lm loss: 2.383337613940239
epoch 0, global step 210, total step 721440, train lm loss: 2.3655078589916227
epoch 0, global step 220, total step 721440, train lm loss: 2.342569851875305
epoch 0, global step 230, total step 721440, train lm loss: 2.382414400577545
epoch 0, global step 240, total step 721440, train lm loss: 2.357599586248398
epoch 0, global step 250, total step 721440, train lm loss: 2.36728530228138
epoch 0, global step 260, total step 721440, train lm loss: 2.3528176218271257
epoch 0, global step 270, total step 721440, train lm loss: 2.3397417843341826
epoch 0, global step 280, total step 721440, train lm loss: 2.335299640893936
epoch 0, global step 290, total step 721440, train lm loss: 2.334272563457489
epoch 0, global step 300, total step 721440, train lm loss: 2.356231951713562
epoch 0, global step 310, total step 721440, train lm loss: 2.346489703655243
epoch 0, global step 320, total step 721440, train lm loss: 2.344374006986618
epoch 0, global step 330, total step 721440, train lm loss: 2.3374361217021944
epoch 0, global step 340, total step 721440, train lm loss: 2.359451267123222
epoch 0, global step 350, total step 721440, train lm loss: 2.349171167612076
epoch 0, global step 360, total step 721440, train lm loss: 2.3376705974340437
epoch 0, global step 370, total step 721440, train lm loss: 2.3292631238698958
epoch 0, global step 380, total step 721440, train lm loss: 2.3313588976860045
epoch 0, global step 390, total step 721440, train lm loss: 2.341523399949074
epoch 0, global step 400, total step 721440, train lm loss: 2.3346590876579283
epoch 0, global step 410, total step 721440, train lm loss: 2.323605453968048
epoch 0, global step 420, total step 721440, train lm loss: 2.3395427972078324
epoch 0, global step 430, total step 721440, train lm loss: 2.3319846987724304
epoch 0, global step 440, total step 721440, train lm loss: 2.327750116586685
epoch 0, global step 450, total step 721440, train lm loss: 2.3300610035657883
epoch 0, global step 460, total step 721440, train lm loss: 2.3264740496873855
epoch 0, global step 470, total step 721440, train lm loss: 2.328410819172859
epoch 0, global step 480, total step 721440, train lm loss: 2.323826548457146
epoch 0, global step 490, total step 721440, train lm loss: 2.325927126407623
epoch 0, global step 500, total step 721440, train lm loss: 2.328062269091606
epoch 0, global step 510, total step 721440, train lm loss: 2.3270431488752363
epoch 0, global step 520, total step 721440, train lm loss: 2.3241519927978516
epoch 0, global step 530, total step 721440, train lm loss: 2.3213663190603255
epoch 0, global step 540, total step 721440, train lm loss: 2.311327260732651
epoch 0, global step 550, total step 721440, train lm loss: 2.3424326151609423
epoch 0, global step 560, total step 721440, train lm loss: 2.328599062561989
epoch 0, global step 570, total step 721440, train lm loss: 2.3239336401224135
epoch 0, global step 580, total step 721440, train lm loss: 2.314295792579651
epoch 0, global step 590, total step 721440, train lm loss: 2.3277305006980895
epoch 0, global step 600, total step 721440, train lm loss: 2.3249065071344375
epoch 0, global step 610, total step 721440, train lm loss: 2.337321180105209
epoch 0, global step 620, total step 721440, train lm loss: 2.3108755350112915
epoch 0, global step 630, total step 721440, train lm loss: 2.3254636943340303
epoch 0, global step 640, total step 721440, train lm loss: 2.3117133647203447
epoch 0, global step 650, total step 721440, train lm loss: 2.314106974005699
epoch 0, global step 660, total step 721440, train lm loss: 2.331553617119789
epoch 0, global step 670, total step 721440, train lm loss: 2.3027353793382646
epoch 0, global step 680, total step 721440, train lm loss: 2.311642661690712
epoch 0, global step 690, total step 721440, train lm loss: 2.3167872607707976
epoch 0, global step 700, total step 721440, train lm loss: 2.321738338470459
epoch 0, global step 710, total step 721440, train lm loss: 2.3321457296609878
epoch 0, global step 720, total step 721440, train lm loss: 2.329233321547508
epoch 0, global step 730, total step 721440, train lm loss: 2.3164357006549836
epoch 0, global step 740, total step 721440, train lm loss: 2.323902001976967
epoch 0, global step 750, total step 721440, train lm loss: 2.3176393508911133
epoch 0, global step 760, total step 721440, train lm loss: 2.324468618631363
epoch 0, global step 770, total step 721440, train lm loss: 2.313769280910492
epoch 0, global step 780, total step 721440, train lm loss: 2.315131586790085
epoch 0, global step 790, total step 721440, train lm loss: 2.3133576244115828
epoch 0, global step 800, total step 721440, train lm loss: 2.314319485425949
epoch 0, global step 810, total step 721440, train lm loss: 2.3085659354925157
epoch 0, global step 820, total step 721440, train lm loss: 2.3213662683963774
epoch 0, global step 830, total step 721440, train lm loss: 2.3183242112398146
epoch 0, global step 840, total step 721440, train lm loss: 2.3099054247140884
epoch 0, global step 850, total step 721440, train lm loss: 2.3139674037694933
epoch 0, global step 860, total step 721440, train lm loss: 2.320941498875618
epoch 0, global step 870, total step 721440, train lm loss: 2.304828095436096
epoch 0, global step 880, total step 721440, train lm loss: 2.3248640179634092
epoch 0, global step 890, total step 721440, train lm loss: 2.309764325618744
epoch 0, global step 900, total step 721440, train lm loss: 2.312568375468254
epoch 0, global step 910, total step 721440, train lm loss: 2.325748488306999
epoch 0, global step 920, total step 721440, train lm loss: 2.3137409716844557
epoch 0, global step 930, total step 721440, train lm loss: 2.314180025458336
epoch 0, global step 940, total step 721440, train lm loss: 2.304318568110466
epoch 0, global step 950, total step 721440, train lm loss: 2.3139054596424105
epoch 0, global step 960, total step 721440, train lm loss: 2.317479294538498
epoch 0, global step 970, total step 721440, train lm loss: 2.320314547419548
epoch 0, global step 980, total step 721440, train lm loss: 2.3166398882865904
epoch 0, global step 990, total step 721440, train lm loss: 2.3250623792409897
epoch 0, global step 1000, total step 721440, train lm loss: 2.307750332355499
epoch 0, global step 1010, total step 721440, train lm loss: 2.315434366464615
epoch 0, global step 1020, total step 721440, train lm loss: 2.3117603987455366
epoch 0, global step 1030, total step 721440, train lm loss: 2.308899438381195
epoch 0, global step 1040, total step 721440, train lm loss: 2.307893827557564
epoch 0, global step 1050, total step 721440, train lm loss: 2.3113900899887083
epoch 0, global step 1060, total step 721440, train lm loss: 2.31181900203228
epoch 0, global step 1070, total step 721440, train lm loss: 2.313424274325371
epoch 0, global step 1080, total step 721440, train lm loss: 2.321720650792122
epoch 0, global step 1090, total step 721440, train lm loss: 2.3109161883592604
epoch 0, global step 1100, total step 721440, train lm loss: 2.3160505324602125
epoch 0, global step 1110, total step 721440, train lm loss: 2.3021224319934843
epoch 0, global step 1120, total step 721440, train lm loss: 2.323046451807022
epoch 0, global step 1130, total step 721440, train lm loss: 2.3092413753271104
epoch 0, global step 1140, total step 721440, train lm loss: 2.3183077037334443
epoch 0, global step 1150, total step 721440, train lm loss: 2.3085527181625367
epoch 0, global step 1160, total step 721440, train lm loss: 2.303636744618416
epoch 0, global step 1170, total step 721440, train lm loss: 2.3130487352609634
epoch 0, global step 1180, total step 721440, train lm loss: 2.3058105051517486
epoch 0, global step 1190, total step 721440, train lm loss: 2.3007051765918733
epoch 0, global step 1200, total step 721440, train lm loss: 2.3089903563261034
epoch 0, global step 1210, total step 721440, train lm loss: 2.311785024404526
epoch 0, global step 1220, total step 721440, train lm loss: 2.3091258317232133
epoch 0, global step 1230, total step 721440, train lm loss: 2.311031758785248
epoch 0, global step 1240, total step 721440, train lm loss: 2.309274363517761
epoch 0, global step 1250, total step 721440, train lm loss: 2.30460410118103
epoch 0, global step 1260, total step 721440, train lm loss: 2.308248129487038
epoch 0, global step 1270, total step 721440, train lm loss: 2.3170037299394606
epoch 0, global step 1280, total step 721440, train lm loss: 2.301348406076431
epoch 0, global step 1290, total step 721440, train lm loss: 2.309915915131569
epoch 0, global step 1300, total step 721440, train lm loss: 2.3100311547517776
epoch 0, global step 1310, total step 721440, train lm loss: 2.306507357954979
epoch 0, global step 1320, total step 721440, train lm loss: 2.3191289573907854
epoch 0, global step 1330, total step 721440, train lm loss: 2.326351448893547
epoch 0, global step 1340, total step 721440, train lm loss: 2.312688282132149
epoch 0, global step 1350, total step 721440, train lm loss: 2.3083473801612855
epoch 0, global step 1360, total step 721440, train lm loss: 2.319363847374916
epoch 0, global step 1370, total step 721440, train lm loss: 2.308558425307274
epoch 0, global step 1380, total step 721440, train lm loss: 2.305957543849945
epoch 0, global step 1390, total step 721440, train lm loss: 2.309961324930191
epoch 0, global step 1400, total step 721440, train lm loss: 2.3019170463085175
epoch 0, global step 1410, total step 721440, train lm loss: 2.312429869174957
epoch 0, global step 1420, total step 721440, train lm loss: 2.313884437084198
epoch 0, global step 1430, total step 721440, train lm loss: 2.3053406178951263
epoch 0, global step 1440, total step 721440, train lm loss: 2.306355881690979
epoch 0, global step 1450, total step 721440, train lm loss: 2.3054824352264403
epoch 0, global step 1460, total step 721440, train lm loss: 2.3204082936048507
epoch 0, global step 1470, total step 721440, train lm loss: 2.305713948607445
epoch 0, global step 1480, total step 721440, train lm loss: 2.3109845370054245
epoch 0, global step 1490, total step 721440, train lm loss: 2.3118657737970354
epoch 0, global step 1500, total step 721440, train lm loss: 2.3148488849401474
epoch 0, global step 1510, total step 721440, train lm loss: 2.304996535181999
epoch 0, global step 1520, total step 721440, train lm loss: 2.313703516125679
epoch 0, global step 1530, total step 721440, train lm loss: 2.3178940445184706
epoch 0, global step 1540, total step 721440, train lm loss: 2.307098740339279
epoch 0, global step 1550, total step 721440, train lm loss: 2.3042535543441773
epoch 0, global step 1560, total step 721440, train lm loss: 2.3159749776124956
epoch 0, global step 1570, total step 721440, train lm loss: 2.3131291389465334
epoch 0, global step 1580, total step 721440, train lm loss: 2.3149866104125976
epoch 0, global step 1590, total step 721440, train lm loss: 2.3066077888011933
epoch 0, global step 1600, total step 721440, train lm loss: 2.3072442382574083
epoch 0, global step 1610, total step 721440, train lm loss: 2.2970015078783037
epoch 0, global step 1620, total step 721440, train lm loss: 2.312362563610077
epoch 0, global step 1630, total step 721440, train lm loss: 2.312209540605545
epoch 0, global step 1640, total step 721440, train lm loss: 2.3079022079706193
epoch 0, global step 1650, total step 721440, train lm loss: 2.303439548611641
epoch 0, global step 1660, total step 721440, train lm loss: 2.3050143748521803
epoch 0, global step 1670, total step 721440, train lm loss: 2.3192337095737456
epoch 0, global step 1680, total step 721440, train lm loss: 2.3072788268327713
epoch 0, global step 1690, total step 721440, train lm loss: 2.306085619330406
epoch 0, global step 1700, total step 721440, train lm loss: 2.3106577932834624
epoch 0, global step 1710, total step 721440, train lm loss: 2.303894704580307
epoch 0, global step 1720, total step 721440, train lm loss: 2.3106088161468508
epoch 0, global step 1730, total step 721440, train lm loss: 2.3191595315933227
epoch 0, global step 1740, total step 721440, train lm loss: 2.31276288330555
epoch 0, global step 1750, total step 721440, train lm loss: 2.3101801335811616
epoch 0, global step 1760, total step 721440, train lm loss: 2.307001477479935
epoch 0, global step 1770, total step 721440, train lm loss: 2.308900552988052
epoch 0, global step 1780, total step 721440, train lm loss: 2.305568113923073
epoch 0, global step 1790, total step 721440, train lm loss: 2.311435842514038
epoch 0, global step 1800, total step 721440, train lm loss: 2.307496243715286
epoch 0, global step 1810, total step 721440, train lm loss: 2.3129783630371095
epoch 0, global step 1820, total step 721440, train lm loss: 2.3071473866701124
epoch 0, global step 1830, total step 721440, train lm loss: 2.304208588600159
epoch 0, global step 1840, total step 721440, train lm loss: 2.3070814102888106
epoch 0, global step 1850, total step 721440, train lm loss: 2.31780050098896
epoch 0, global step 1860, total step 721440, train lm loss: 2.3014362275600435
epoch 0, global step 1870, total step 721440, train lm loss: 2.30540908575058
epoch 0, global step 1880, total step 721440, train lm loss: 2.309238773584366
epoch 0, global step 1890, total step 721440, train lm loss: 2.3095813661813738
epoch 0, global step 1900, total step 721440, train lm loss: 2.3131578266620636
epoch 0, global step 1910, total step 721440, train lm loss: 2.301818808913231
epoch 0, global step 1920, total step 721440, train lm loss: 2.3132251262664796
epoch 0, global step 1930, total step 721440, train lm loss: 2.3116794735193253
epoch 0, global step 1940, total step 721440, train lm loss: 2.3047549396753313
epoch 0, global step 1950, total step 721440, train lm loss: 2.3044745534658433
epoch 0, global step 1960, total step 721440, train lm loss: 2.3169257014989855
epoch 0, global step 1970, total step 721440, train lm loss: 2.3087181001901627
epoch 0, global step 1980, total step 721440, train lm loss: 2.3078513950109483
epoch 0, global step 1990, total step 721440, train lm loss: 2.297080546617508
epoch 0, global step 2000, total step 721440, train lm loss: 2.3136998116970062
epoch 0, global step 2010, total step 721440, train lm loss: 2.3147836565971374
epoch 0, global step 2020, total step 721440, train lm loss: 2.3078458219766618
epoch 0, global step 2030, total step 721440, train lm loss: 2.3125677913427354
epoch 0, global step 2040, total step 721440, train lm loss: 2.3049678951501846
epoch 0, global step 2050, total step 721440, train lm loss: 2.3002792060375215
epoch 0, global step 2060, total step 721440, train lm loss: 2.310621416568756
epoch 0, global step 2070, total step 721440, train lm loss: 2.3121770560741424
epoch 0, global step 2080, total step 721440, train lm loss: 2.306884080171585
epoch 0, global step 2090, total step 721440, train lm loss: 2.321273848414421
epoch 0, global step 2100, total step 721440, train lm loss: 2.2993815541267395
epoch 0, global step 2110, total step 721440, train lm loss: 2.301999905705452
epoch 0, global step 2120, total step 721440, train lm loss: 2.3006815969944
epoch 0, global step 2130, total step 721440, train lm loss: 2.3018606662750245
epoch 0, global step 2140, total step 721440, train lm loss: 2.2859856128692626
epoch 0, global step 2150, total step 721440, train lm loss: 2.2937087953090667
epoch 0, global step 2160, total step 721440, train lm loss: 2.3011349350214005
epoch 0, global step 2170, total step 721440, train lm loss: 2.3110187888145446
epoch 0, global step 2180, total step 721440, train lm loss: 2.2904159128665924
epoch 0, global step 2190, total step 721440, train lm loss: 2.311668521165848
epoch 0, global step 2200, total step 721440, train lm loss: 2.300633415579796
epoch 0, global step 2210, total step 721440, train lm loss: 2.2984040051698686
epoch 0, global step 2220, total step 721440, train lm loss: 2.30255608856678
epoch 0, global step 2230, total step 721440, train lm loss: 2.2970474302768706
epoch 0, global step 2240, total step 721440, train lm loss: 2.298305147886276
epoch 0, global step 2250, total step 721440, train lm loss: 2.2847433894872666
epoch 0, global step 2260, total step 721440, train lm loss: 2.295208939909935
epoch 0, global step 2270, total step 721440, train lm loss: 2.297461524605751
epoch 0, global step 2280, total step 721440, train lm loss: 2.281886675953865
epoch 0, global step 2290, total step 721440, train lm loss: 2.281472238898277
epoch 0, global step 2300, total step 721440, train lm loss: 2.308729428052902
epoch 0, global step 2310, total step 721440, train lm loss: 2.2946998447179796
epoch 0, global step 2320, total step 721440, train lm loss: 2.300594574213028
epoch 0, global step 2330, total step 721440, train lm loss: 2.2726248621940615
epoch 0, global step 2340, total step 721440, train lm loss: 2.2720966666936873
epoch 0, global step 2350, total step 721440, train lm loss: 2.2737979516386986
epoch 0, global step 2360, total step 721440, train lm loss: 2.3111269205808638
epoch 0, global step 2370, total step 721440, train lm loss: 2.288511151075363
epoch 0, global step 2380, total step 721440, train lm loss: 2.281795412302017
epoch 0, global step 2390, total step 721440, train lm loss: 2.2750302493572234
epoch 0, global step 2400, total step 721440, train lm loss: 2.2860088467597963
epoch 0, global step 2410, total step 721440, train lm loss: 2.2838474929332735
epoch 0, global step 2420, total step 721440, train lm loss: 2.2846307665109635
epoch 0, global step 2430, total step 721440, train lm loss: 2.2816908180713655
epoch 0, global step 2440, total step 721440, train lm loss: 2.2872004091739653
epoch 0, global step 2450, total step 721440, train lm loss: 2.2709690898656847
epoch 0, global step 2460, total step 721440, train lm loss: 2.297200357913971
epoch 0, global step 2470, total step 721440, train lm loss: 2.2810331523418426
epoch 0, global step 2480, total step 721440, train lm loss: 2.282820026576519
epoch 0, global step 2490, total step 721440, train lm loss: 2.2785303622484205
epoch 0, global step 2500, total step 721440, train lm loss: 2.280525231361389
epoch 0, global step 2510, total step 721440, train lm loss: 2.294944629073143
epoch 0, global step 2520, total step 721440, train lm loss: 2.303425070643425
epoch 0, global step 2530, total step 721440, train lm loss: 2.2999601781368257
epoch 0, global step 2540, total step 721440, train lm loss: 2.272220605611801
epoch 0, global step 2550, total step 721440, train lm loss: 2.3112526446580888
epoch 0, global step 2560, total step 721440, train lm loss: 2.286691451072693
epoch 0, global step 2570, total step 721440, train lm loss: 2.2858021378517153
epoch 0, global step 2580, total step 721440, train lm loss: 2.275970220565796
epoch 0, global step 2590, total step 721440, train lm loss: 2.2647332072257997
epoch 0, global step 2600, total step 721440, train lm loss: 2.276260021328926
epoch 0, global step 2610, total step 721440, train lm loss: 2.2659648180007936
epoch 0, global step 2620, total step 721440, train lm loss: 2.283808720111847
epoch 0, global step 2630, total step 721440, train lm loss: 2.2716876447200773
epoch 0, global step 2640, total step 721440, train lm loss: 2.2613248378038406
epoch 0, global step 2650, total step 721440, train lm loss: 2.2759606778621673
epoch 0, global step 2660, total step 721440, train lm loss: 2.266438679397106
epoch 0, global step 2670, total step 721440, train lm loss: 2.2653135120868684
epoch 0, global step 2680, total step 721440, train lm loss: 2.2645417183637617
epoch 0, global step 2690, total step 721440, train lm loss: 2.243546876311302
epoch 0, global step 2700, total step 721440, train lm loss: 2.2418016463518144
epoch 0, global step 2710, total step 721440, train lm loss: 2.2254712507128716
epoch 0, global step 2720, total step 721440, train lm loss: 2.250917059183121
epoch 0, global step 2730, total step 721440, train lm loss: 2.225453233718872
epoch 0, global step 2740, total step 721440, train lm loss: 2.195491710305214
epoch 0, global step 2750, total step 721440, train lm loss: 2.1731875821948052
epoch 0, global step 2760, total step 721440, train lm loss: 2.1953037112951277
epoch 0, global step 2770, total step 721440, train lm loss: 2.156294234097004
epoch 0, global step 2780, total step 721440, train lm loss: 2.142482402920723
epoch 0, global step 2790, total step 721440, train lm loss: 2.149974486231804
epoch 0, global step 2800, total step 721440, train lm loss: 2.0803772687911986
epoch 0, global step 2810, total step 721440, train lm loss: 2.1263759806752205
epoch 0, global step 2820, total step 721440, train lm loss: 2.1018817633390428
epoch 0, global step 2830, total step 721440, train lm loss: 2.0598724499344825
epoch 0, global step 2840, total step 721440, train lm loss: 2.122745680809021
epoch 0, global step 2850, total step 721440, train lm loss: 2.047813203930855
epoch 0, global step 2860, total step 721440, train lm loss: 2.0088653221726416
epoch 0, global step 2870, total step 721440, train lm loss: 1.9900343030691148
epoch 0, global step 2880, total step 721440, train lm loss: 1.9429581835865974
epoch 0, global step 2890, total step 721440, train lm loss: 1.93662878125906
epoch 0, global step 2900, total step 721440, train lm loss: 1.9172791555523871
epoch 0, global step 2910, total step 721440, train lm loss: 1.9108643025159835
epoch 0, global step 2920, total step 721440, train lm loss: 1.9285731464624405
epoch 0, global step 2930, total step 721440, train lm loss: 1.8938829436898232
epoch 0, global step 2940, total step 721440, train lm loss: 1.8328000351786613
epoch 0, global step 2950, total step 721440, train lm loss: 1.9049771800637245
epoch 0, global step 2960, total step 721440, train lm loss: 1.8553137734532357
epoch 0, global step 2970, total step 721440, train lm loss: 1.8836484387516976
epoch 0, global step 2980, total step 721440, train lm loss: 1.7609640806913376
epoch 0, global step 2990, total step 721440, train lm loss: 1.760716985166073
epoch 0, global step 3000, total step 721440, train lm loss: 1.767945186793804
epoch 0, global step 3010, total step 721440, train lm loss: 1.8114104449748993
epoch 0, global step 3020, total step 721440, train lm loss: 1.7935939088463784
epoch 0, global step 3030, total step 721440, train lm loss: 1.7724479675292968
epoch 0, global step 3040, total step 721440, train lm loss: 1.788553887605667
epoch 0, global step 3050, total step 721440, train lm loss: 1.7404080219566822
epoch 0, global step 3060, total step 721440, train lm loss: 1.705513282865286
epoch 0, global step 3070, total step 721440, train lm loss: 1.652033244073391
epoch 0, global step 3080, total step 721440, train lm loss: 1.732772122323513
epoch 0, global step 3090, total step 721440, train lm loss: 1.6410346895456314
epoch 0, global step 3100, total step 721440, train lm loss: 1.6120296888053418
epoch 0, global step 3110, total step 721440, train lm loss: 1.6451363295316697
epoch 0, global step 3120, total step 721440, train lm loss: 1.5875666044652461
epoch 0, global step 3130, total step 721440, train lm loss: 1.629625177383423
epoch 0, global step 3140, total step 721440, train lm loss: 1.6286842405796051
epoch 0, global step 3150, total step 721440, train lm loss: 1.6278761856257915
epoch 0, global step 3160, total step 721440, train lm loss: 1.5748239956796168
epoch 0, global step 3170, total step 721440, train lm loss: 1.5282966062426566
epoch 0, global step 3180, total step 721440, train lm loss: 1.529173991829157
epoch 0, global step 3190, total step 721440, train lm loss: 1.6202396914362907
epoch 0, global step 3200, total step 721440, train lm loss: 1.5675187312066554
epoch 0, global step 3210, total step 721440, train lm loss: 1.5684625126421452
epoch 0, global step 3220, total step 721440, train lm loss: 1.5039964854717254
epoch 0, global step 3230, total step 721440, train lm loss: 1.4655377835035324
epoch 0, global step 3240, total step 721440, train lm loss: 1.5110609479248525
epoch 0, global step 3250, total step 721440, train lm loss: 1.5817016921937466
epoch 0, global step 3260, total step 721440, train lm loss: 1.5356889620423317
epoch 0, global step 3270, total step 721440, train lm loss: 1.4858815759420394
epoch 0, global step 3280, total step 721440, train lm loss: 1.4505046352744102
epoch 0, global step 3290, total step 721440, train lm loss: 1.4130205892026424
epoch 0, global step 3300, total step 721440, train lm loss: 1.4475139938294888
epoch 0, global step 3310, total step 721440, train lm loss: 1.487342682480812
epoch 0, global step 3320, total step 721440, train lm loss: 1.525667592138052
epoch 0, global step 3330, total step 721440, train lm loss: 1.4877873934805392
epoch 0, global step 3340, total step 721440, train lm loss: 1.4841897629201413
epoch 0, global step 3350, total step 721440, train lm loss: 1.3521538279950618
epoch 0, global step 3360, total step 721440, train lm loss: 1.4626354627311229
epoch 0, global step 3370, total step 721440, train lm loss: 1.363683069497347
epoch 0, global step 3380, total step 721440, train lm loss: 1.4161398999392987
epoch 0, global step 3390, total step 721440, train lm loss: 1.3604882188141345
epoch 0, global step 3400, total step 721440, train lm loss: 1.4163008127361536
epoch 0, global step 3410, total step 721440, train lm loss: 1.380392498522997
epoch 0, global step 3420, total step 721440, train lm loss: 1.306291511654854
epoch 0, global step 3430, total step 721440, train lm loss: 1.3625314258038999
epoch 0, global step 3440, total step 721440, train lm loss: 1.4132690399885177
epoch 0, global step 3450, total step 721440, train lm loss: 1.407697208970785
epoch 0, global step 3460, total step 721440, train lm loss: 1.3767220683395862
epoch 0, global step 3470, total step 721440, train lm loss: 1.3223921358585358
epoch 0, global step 3480, total step 721440, train lm loss: 1.4278296105563641
epoch 0, global step 3490, total step 721440, train lm loss: 1.2950301043689252
epoch 0, global step 3500, total step 721440, train lm loss: 1.3338843770325184
epoch 0, global step 3510, total step 721440, train lm loss: 1.335680815577507
epoch 0, global step 3520, total step 721440, train lm loss: 1.2910010367631912
epoch 0, global step 3530, total step 721440, train lm loss: 1.4190435692667962
epoch 0, global step 3540, total step 721440, train lm loss: 1.3651840686798096
epoch 0, global step 3550, total step 721440, train lm loss: 1.3450592555105687
epoch 0, global step 3560, total step 721440, train lm loss: 1.2730184473097323
epoch 0, global step 3570, total step 721440, train lm loss: 1.3409457944333554
epoch 0, global step 3580, total step 721440, train lm loss: 1.2361559391021728
epoch 0, global step 3590, total step 721440, train lm loss: 1.2812194049358367
epoch 0, global step 3600, total step 721440, train lm loss: 1.2955663960427046
epoch 0, global step 3610, total step 721440, train lm loss: 1.3415286339819432
epoch 0, global step 3620, total step 721440, train lm loss: 1.2636368945240974
epoch 0, global step 3630, total step 721440, train lm loss: 1.2962228044867516
epoch 0, global step 3640, total step 721440, train lm loss: 1.2905311159789563
epoch 0, global step 3650, total step 721440, train lm loss: 1.268434302508831
epoch 0, global step 3660, total step 721440, train lm loss: 1.3073468886315822
epoch 0, global step 3670, total step 721440, train lm loss: 1.2964867554605006
epoch 0, global step 3680, total step 721440, train lm loss: 1.2491101801395417
epoch 0, global step 3690, total step 721440, train lm loss: 1.2766407053917646
epoch 0, global step 3700, total step 721440, train lm loss: 1.2638952285051346
epoch 0, global step 3710, total step 721440, train lm loss: 1.197409802675247
epoch 0, global step 3720, total step 721440, train lm loss: 1.3028569467365743
epoch 0, global step 3730, total step 721440, train lm loss: 1.3543685115873814
epoch 0, global step 3740, total step 721440, train lm loss: 1.203165354952216
epoch 0, global step 3750, total step 721440, train lm loss: 1.2960199933499097
epoch 0, global step 3760, total step 721440, train lm loss: 1.192113322392106
epoch 0, global step 3770, total step 721440, train lm loss: 1.2276677139103414
epoch 0, global step 3780, total step 721440, train lm loss: 1.1669022917747498
epoch 0, global step 3790, total step 721440, train lm loss: 1.2728582881391048
epoch 0, global step 3800, total step 721440, train lm loss: 1.2467900574207307
epoch 0, global step 3810, total step 721440, train lm loss: 1.2035077854990959
epoch 0, global step 3820, total step 721440, train lm loss: 1.2655494466423989
epoch 0, global step 3830, total step 721440, train lm loss: 1.246815589815378
epoch 0, global step 3840, total step 721440, train lm loss: 1.2346444632858038
epoch 0, global step 3850, total step 721440, train lm loss: 1.1572119139134884
epoch 0, global step 3860, total step 721440, train lm loss: 1.2904006220400333
epoch 0, global step 3870, total step 721440, train lm loss: 1.2869040682911872
epoch 0, global step 3880, total step 721440, train lm loss: 1.1947716273367406
epoch 0, global step 3890, total step 721440, train lm loss: 1.2140792492777108
epoch 0, global step 3900, total step 721440, train lm loss: 1.1947443880140782
epoch 0, global step 3910, total step 721440, train lm loss: 1.1873160030692815
epoch 0, global step 3920, total step 721440, train lm loss: 1.1581217136234045
epoch 0, global step 3930, total step 721440, train lm loss: 1.1959388956427575
epoch 0, global step 3940, total step 721440, train lm loss: 1.1371355205774307
epoch 0, global step 3950, total step 721440, train lm loss: 1.2042303543537856
epoch 0, global step 3960, total step 721440, train lm loss: 1.2313484482467174
epoch 0, global step 3970, total step 721440, train lm loss: 1.1797018773853778
epoch 0, global step 3980, total step 721440, train lm loss: 1.2237811211496592
epoch 0, global step 3990, total step 721440, train lm loss: 1.1243615664541722
epoch 0, global step 4000, total step 721440, train lm loss: 1.127190937846899
epoch 0, global step 4010, total step 721440, train lm loss: 1.2355535000562667
epoch 0, global step 4020, total step 721440, train lm loss: 1.2411478020250797
epoch 0, global step 4030, total step 721440, train lm loss: 1.1457052774727345
epoch 0, global step 4040, total step 721440, train lm loss: 1.186395960301161
epoch 0, global step 4050, total step 721440, train lm loss: 1.1554544556885957
epoch 0, global step 4060, total step 721440, train lm loss: 1.171407698839903
epoch 0, global step 4070, total step 721440, train lm loss: 1.135496686398983
epoch 0, global step 4080, total step 721440, train lm loss: 1.203143386170268
epoch 0, global step 4090, total step 721440, train lm loss: 1.121809509396553
epoch 0, global step 4100, total step 721440, train lm loss: 1.1690567661076785
epoch 0, global step 4110, total step 721440, train lm loss: 1.093439180776477
epoch 0, global step 4120, total step 721440, train lm loss: 1.127493679523468
epoch 0, global step 4130, total step 721440, train lm loss: 1.0920460518449544
epoch 0, global step 4140, total step 721440, train lm loss: 1.1709198225289583
epoch 0, global step 4150, total step 721440, train lm loss: 1.1162824548780919
epoch 0, global step 4160, total step 721440, train lm loss: 1.1487513959407807
epoch 0, global step 4170, total step 721440, train lm loss: 1.0879247583448888
epoch 0, global step 4180, total step 721440, train lm loss: 1.123810423910618
epoch 0, global step 4190, total step 721440, train lm loss: 1.0934348665177822
epoch 0, global step 4200, total step 721440, train lm loss: 1.1306862246245146
epoch 0, global step 4210, total step 721440, train lm loss: 1.2102011512964963
epoch 0, global step 4220, total step 721440, train lm loss: 1.0897500157356261
epoch 0, global step 4230, total step 721440, train lm loss: 1.1019584354013205
epoch 0, global step 4240, total step 721440, train lm loss: 1.1589066054672004
epoch 0, global step 4250, total step 721440, train lm loss: 1.1205228991806506
epoch 0, global step 4260, total step 721440, train lm loss: 1.1484541654586793
epoch 0, global step 4270, total step 721440, train lm loss: 1.0898118186742067
epoch 0, global step 4280, total step 721440, train lm loss: 1.1285902161151171
epoch 0, global step 4290, total step 721440, train lm loss: 1.080649357661605
epoch 0, global step 4300, total step 721440, train lm loss: 1.0641660027205944
epoch 0, global step 4310, total step 721440, train lm loss: 1.0984610065817833
epoch 0, global step 4320, total step 721440, train lm loss: 1.0695498172193765
epoch 0, global step 4330, total step 721440, train lm loss: 1.11846631616354
epoch 0, global step 4340, total step 721440, train lm loss: 1.1817635636776687
epoch 0, global step 4350, total step 721440, train lm loss: 1.0335087675601244
epoch 0, global step 4360, total step 721440, train lm loss: 1.1418716311454773
epoch 0, global step 4370, total step 721440, train lm loss: 1.076553288847208
epoch 0, global step 4380, total step 721440, train lm loss: 1.1060908582061528
epoch 0, global step 4390, total step 721440, train lm loss: 1.0341967657208442
epoch 0, global step 4400, total step 721440, train lm loss: 1.0555006494745611
epoch 0, global step 4410, total step 721440, train lm loss: 1.0171261373907328
epoch 0, global step 4420, total step 721440, train lm loss: 1.0512804612517357
epoch 0, global step 4430, total step 721440, train lm loss: 1.0582104302942752
epoch 0, global step 4440, total step 721440, train lm loss: 0.9761195380240679
epoch 0, global step 4450, total step 721440, train lm loss: 1.1241126608103513
epoch 0, global step 4460, total step 721440, train lm loss: 1.1131680324673652
epoch 0, global step 4470, total step 721440, train lm loss: 1.071790088713169
epoch 0, global step 4480, total step 721440, train lm loss: 1.087964415550232
epoch 0, global step 4490, total step 721440, train lm loss: 1.1993830766528846
epoch 0, global step 4500, total step 721440, train lm loss: 1.1641636162996292
epoch 0, global step 4510, total step 721440, train lm loss: 1.1214358527213335
epoch 0, global step 4520, total step 721440, train lm loss: 0.9643991343677044
epoch 0, global step 4530, total step 721440, train lm loss: 1.053451957926154
epoch 0, global step 4540, total step 721440, train lm loss: 1.0584149207919835
epoch 0, global step 4550, total step 721440, train lm loss: 1.1306461971253157
epoch 0, global step 4560, total step 721440, train lm loss: 1.0263038020581008
epoch 0, global step 4570, total step 721440, train lm loss: 1.0299106687307358
epoch 0, global step 4580, total step 721440, train lm loss: 1.0520674992352723
epoch 0, global step 4590, total step 721440, train lm loss: 1.0589541763067245
epoch 0, global step 4600, total step 721440, train lm loss: 1.1192474145442248
epoch 0, global step 4610, total step 721440, train lm loss: 1.1027450334280728
epoch 0, global step 4620, total step 721440, train lm loss: 1.0437862277030945
epoch 0, global step 4630, total step 721440, train lm loss: 1.1383993070572616
epoch 0, global step 4640, total step 721440, train lm loss: 1.108360794186592
epoch 0, global step 4650, total step 721440, train lm loss: 1.0206835746765137
epoch 0, global step 4660, total step 721440, train lm loss: 1.0424800358712674
epoch 0, global step 4670, total step 721440, train lm loss: 1.1439928878098726
epoch 0, global step 4680, total step 721440, train lm loss: 1.0425235349684954
epoch 0, global step 4690, total step 721440, train lm loss: 1.090380272641778
epoch 0, global step 4700, total step 721440, train lm loss: 0.9966089800000191
epoch 0, global step 4710, total step 721440, train lm loss: 1.0943058349192143
epoch 0, global step 4720, total step 721440, train lm loss: 1.1223984241485596
epoch 0, global step 4730, total step 721440, train lm loss: 1.1159830305725336
epoch 0, global step 4740, total step 721440, train lm loss: 1.1221879962831736
epoch 0, global step 4750, total step 721440, train lm loss: 1.0574891049414874
epoch 0, global step 4760, total step 721440, train lm loss: 0.9964964389801025
epoch 0, global step 4770, total step 721440, train lm loss: 1.0638186369091271
epoch 0, global step 4780, total step 721440, train lm loss: 1.0829657778143882
epoch 0, global step 4790, total step 721440, train lm loss: 1.0336893245577812
epoch 0, global step 4800, total step 721440, train lm loss: 1.0251247655600308
epoch 0, global step 4810, total step 721440, train lm loss: 1.0092314127832651
epoch 0, global step 4820, total step 721440, train lm loss: 1.028377589210868
epoch 0, global step 4830, total step 721440, train lm loss: 0.9563770189881324
epoch 0, global step 4840, total step 721440, train lm loss: 1.0136971632018685
epoch 0, global step 4850, total step 721440, train lm loss: 1.0344200763851403
epoch 0, global step 4860, total step 721440, train lm loss: 1.0072226330637932
epoch 0, global step 4870, total step 721440, train lm loss: 0.992209181189537
epoch 0, global step 4880, total step 721440, train lm loss: 1.0171299446374178
epoch 0, global step 4890, total step 721440, train lm loss: 1.0052581761032342
epoch 0, global step 4900, total step 721440, train lm loss: 0.9205800805240869
epoch 0, global step 4910, total step 721440, train lm loss: 1.0761802848428488
epoch 0, global step 4920, total step 721440, train lm loss: 0.9198119524866343
epoch 0, global step 4930, total step 721440, train lm loss: 1.051159128919244
epoch 0, global step 4940, total step 721440, train lm loss: 1.0360640160739423
epoch 0, global step 4950, total step 721440, train lm loss: 1.0082244146615267
epoch 0, global step 4960, total step 721440, train lm loss: 0.9064912557601928
epoch 0, global step 4970, total step 721440, train lm loss: 1.0059208946302534
epoch 0, global step 4980, total step 721440, train lm loss: 1.0286543756723403
epoch 0, global step 4990, total step 721440, train lm loss: 0.9677245706319809
epoch 0, global step 5000, total step 721440, train lm loss: 1.0129607893526553
epoch 0, global step 5010, total step 721440, train lm loss: 1.058984936028719
epoch 0, global step 5020, total step 721440, train lm loss: 0.985844068787992
epoch 0, global step 5030, total step 721440, train lm loss: 1.0054659370332957
epoch 0, global step 5040, total step 721440, train lm loss: 1.0978774707764387
epoch 0, global step 5050, total step 721440, train lm loss: 1.0404770039021969
epoch 0, global step 5060, total step 721440, train lm loss: 1.0089748583734035
epoch 0, global step 5070, total step 721440, train lm loss: 0.9669810853898525
epoch 0, global step 5080, total step 721440, train lm loss: 0.999068221449852
epoch 0, global step 5090, total step 721440, train lm loss: 1.0642182651907206
epoch 0, global step 5100, total step 721440, train lm loss: 1.0290754701942206
epoch 0, global step 5110, total step 721440, train lm loss: 0.9987074866890907
epoch 0, global step 5120, total step 721440, train lm loss: 0.9724749624729156
epoch 0, global step 5130, total step 721440, train lm loss: 1.0103924859315156
epoch 0, global step 5140, total step 721440, train lm loss: 1.0078836292028428
epoch 0, global step 5150, total step 721440, train lm loss: 0.9842366425320506
epoch 0, global step 5160, total step 721440, train lm loss: 1.055840909294784
epoch 0, global step 5170, total step 721440, train lm loss: 0.9888474926352501
epoch 0, global step 5180, total step 721440, train lm loss: 1.102847632393241
epoch 0, global step 5190, total step 721440, train lm loss: 0.9617805242538452
epoch 0, global step 5200, total step 721440, train lm loss: 1.0157078351825475
epoch 0, global step 5210, total step 721440, train lm loss: 0.9911388359963894
epoch 0, global step 5220, total step 721440, train lm loss: 1.0417959921061992
epoch 0, global step 5230, total step 721440, train lm loss: 1.0642339527606963
epoch 0, global step 5240, total step 721440, train lm loss: 0.9413622204214335
epoch 0, global step 5250, total step 721440, train lm loss: 1.0177595602348446
epoch 0, global step 5260, total step 721440, train lm loss: 0.939103557355702
epoch 0, global step 5270, total step 721440, train lm loss: 0.9556605901569128
epoch 0, global step 5280, total step 721440, train lm loss: 0.955134098790586
epoch 0, global step 5290, total step 721440, train lm loss: 0.9836929973214865
epoch 0, global step 5300, total step 721440, train lm loss: 1.0229590598493814
epoch 0, global step 5310, total step 721440, train lm loss: 0.9738323710858822
epoch 0, global step 5320, total step 721440, train lm loss: 0.9902396108955145
epoch 0, global step 5330, total step 721440, train lm loss: 0.9822348384186625
epoch 0, global step 5340, total step 721440, train lm loss: 1.0214844558387994
epoch 0, global step 5350, total step 721440, train lm loss: 0.9314613392576575
epoch 0, global step 5360, total step 721440, train lm loss: 0.9008663892745972
epoch 0, global step 5370, total step 721440, train lm loss: 0.9922560267150402
epoch 0, global step 5380, total step 721440, train lm loss: 0.9589374359697104
epoch 0, global step 5390, total step 721440, train lm loss: 1.014638267084956
epoch 0, global step 5400, total step 721440, train lm loss: 0.9373134907335043
epoch 0, global step 5410, total step 721440, train lm loss: 1.0453468438237905
epoch 0, global step 5420, total step 721440, train lm loss: 1.0224667388945818
epoch 0, global step 5430, total step 721440, train lm loss: 0.9663782585412264
epoch 0, global step 5440, total step 721440, train lm loss: 0.9723757360130548
epoch 0, global step 5450, total step 721440, train lm loss: 1.001366863027215
epoch 0, global step 5460, total step 721440, train lm loss: 0.9482502598315478
epoch 0, global step 5470, total step 721440, train lm loss: 0.9239487547427416
epoch 0, global step 5480, total step 721440, train lm loss: 0.9756338525563478
epoch 0, global step 5490, total step 721440, train lm loss: 1.008080667257309
epoch 0, global step 5500, total step 721440, train lm loss: 0.9365690451115369
epoch 0, global step 5510, total step 721440, train lm loss: 1.0238951072096825
epoch 0, global step 5520, total step 721440, train lm loss: 0.88160867895931
epoch 0, global step 5530, total step 721440, train lm loss: 0.9638221058994532
epoch 0, global step 5540, total step 721440, train lm loss: 0.9836180355399847
epoch 0, global step 5550, total step 721440, train lm loss: 0.9898875458166003
epoch 0, global step 5560, total step 721440, train lm loss: 0.9543954141438007
epoch 0, global step 5570, total step 721440, train lm loss: 0.9606877893209458
epoch 0, global step 5580, total step 721440, train lm loss: 0.9795755514875054
epoch 0, global step 5590, total step 721440, train lm loss: 0.9088577596470714
epoch 0, global step 5600, total step 721440, train lm loss: 0.892794643715024
epoch 0, global step 5610, total step 721440, train lm loss: 0.9133755112066865
epoch 0, global step 5620, total step 721440, train lm loss: 0.9003343533724546
epoch 0, global step 5630, total step 721440, train lm loss: 0.9037079099565745
epoch 0, global step 5640, total step 721440, train lm loss: 0.9564359864220023
epoch 0, global step 5650, total step 721440, train lm loss: 0.9928467839956283
epoch 0, global step 5660, total step 721440, train lm loss: 0.9638757906854153
epoch 0, global step 5670, total step 721440, train lm loss: 0.9298187432810664
epoch 0, global step 5680, total step 721440, train lm loss: 0.9242080919444561
epoch 0, global step 5690, total step 721440, train lm loss: 0.8982396863400937
epoch 0, global step 5700, total step 721440, train lm loss: 1.0179600577801466
epoch 0, global step 5710, total step 721440, train lm loss: 0.9194062141701579
epoch 0, global step 5720, total step 721440, train lm loss: 0.866066056676209
epoch 0, global step 5730, total step 721440, train lm loss: 0.9279933977872133
epoch 0, global step 5740, total step 721440, train lm loss: 0.9056005144491792
epoch 0, global step 5750, total step 721440, train lm loss: 0.9054625734686852
epoch 0, global step 5760, total step 721440, train lm loss: 0.9001831602305174
epoch 0, global step 5770, total step 721440, train lm loss: 0.9165590200573206
epoch 0, global step 5780, total step 721440, train lm loss: 0.9154365627095103
epoch 0, global step 5790, total step 721440, train lm loss: 0.894950195401907
epoch 0, global step 5800, total step 721440, train lm loss: 0.9493514206260443
epoch 0, global step 5810, total step 721440, train lm loss: 0.8472754569724202
epoch 0, global step 5820, total step 721440, train lm loss: 0.8992543522268533
epoch 0, global step 5830, total step 721440, train lm loss: 1.001297378540039
epoch 0, global step 5840, total step 721440, train lm loss: 0.8734701987355947
epoch 0, global step 5850, total step 721440, train lm loss: 0.9093592124059796
epoch 0, global step 5860, total step 721440, train lm loss: 0.8919260989874601
epoch 0, global step 5870, total step 721440, train lm loss: 0.9657829381525517
epoch 0, global step 5880, total step 721440, train lm loss: 0.9493816087953746
epoch 0, global step 5890, total step 721440, train lm loss: 0.9449745444580913
epoch 0, global step 5900, total step 721440, train lm loss: 0.95474914573133
epoch 0, global step 5910, total step 721440, train lm loss: 0.995147286169231
epoch 0, global step 5920, total step 721440, train lm loss: 0.9290635880082846
epoch 0, global step 5930, total step 721440, train lm loss: 0.9545392073690891
epoch 0, global step 5940, total step 721440, train lm loss: 0.9538391713052988
epoch 0, global step 5950, total step 721440, train lm loss: 0.9659705406054855
epoch 0, global step 5960, total step 721440, train lm loss: 0.9232430577278137
epoch 0, global step 5970, total step 721440, train lm loss: 0.9079814814031124
epoch 0, global step 5980, total step 721440, train lm loss: 0.8835786746814847
epoch 0, global step 5990, total step 721440, train lm loss: 0.9831253301352263
epoch 0, global step 6000, total step 721440, train lm loss: 1.0235011767596007
epoch 0, global step 6010, total step 721440, train lm loss: 0.9041977524757385
epoch 0, global step 6020, total step 721440, train lm loss: 0.8981545040383935
epoch 0, global step 6030, total step 721440, train lm loss: 0.8620892023667693
epoch 0, global step 6040, total step 721440, train lm loss: 0.8851571898907423
epoch 0, global step 6050, total step 721440, train lm loss: 0.8799647381529212
epoch 0, global step 6060, total step 721440, train lm loss: 0.9903843112289905
epoch 0, global step 6070, total step 721440, train lm loss: 0.9297272436320781
epoch 0, global step 6080, total step 721440, train lm loss: 0.9169001396745443
epoch 0, global step 6090, total step 721440, train lm loss: 0.9716787114739418
epoch 0, global step 6100, total step 721440, train lm loss: 0.9587695993483066
epoch 0, global step 6110, total step 721440, train lm loss: 0.8951499108225107
epoch 0, global step 6120, total step 721440, train lm loss: 0.9215529460459948
epoch 0, global step 6130, total step 721440, train lm loss: 0.9877668434754014
epoch 0, global step 6140, total step 721440, train lm loss: 0.837970183044672
epoch 0, global step 6150, total step 721440, train lm loss: 0.8634762343019247
epoch 0, global step 6160, total step 721440, train lm loss: 0.9153357082977891
epoch 0, global step 6170, total step 721440, train lm loss: 0.9936872130259872
epoch 0, global step 6180, total step 721440, train lm loss: 0.8667281800881028
epoch 0, global step 6190, total step 721440, train lm loss: 0.9435989134013653
epoch 0, global step 6200, total step 721440, train lm loss: 0.9081445287913084
epoch 0, global step 6210, total step 721440, train lm loss: 0.9663294464349746
epoch 0, global step 6220, total step 721440, train lm loss: 0.9458598788827658
epoch 0, global step 6230, total step 721440, train lm loss: 0.8521857034415007
epoch 0, global step 6240, total step 721440, train lm loss: 0.9123764915391803
epoch 0, global step 6250, total step 721440, train lm loss: 0.9350937027484179
epoch 0, global step 6260, total step 721440, train lm loss: 0.8608481835573911
epoch 0, global step 6270, total step 721440, train lm loss: 0.932353699952364
epoch 0, global step 6280, total step 721440, train lm loss: 0.9321834994480014
epoch 0, global step 6290, total step 721440, train lm loss: 0.8796137988567352
epoch 0, global step 6300, total step 721440, train lm loss: 0.8842465143650771
epoch 0, global step 6310, total step 721440, train lm loss: 0.7995141096413135
epoch 0, global step 6320, total step 721440, train lm loss: 0.9641317963600159
epoch 0, global step 6330, total step 721440, train lm loss: 0.8321679722517729
epoch 0, global step 6340, total step 721440, train lm loss: 0.928255939669907
epoch 0, global step 6350, total step 721440, train lm loss: 0.9879219707101583
epoch 0, global step 6360, total step 721440, train lm loss: 0.8364043908193708
epoch 0, global step 6370, total step 721440, train lm loss: 0.8419724369421602
epoch 0, global step 6380, total step 721440, train lm loss: 0.9031605993397533
epoch 0, global step 6390, total step 721440, train lm loss: 0.9374344630166889
epoch 0, global step 6400, total step 721440, train lm loss: 0.9881142500787974
epoch 0, global step 6410, total step 721440, train lm loss: 0.9199160940945148
epoch 0, global step 6420, total step 721440, train lm loss: 0.8900988474488258
epoch 0, global step 6430, total step 721440, train lm loss: 0.9194913119077682
epoch 0, global step 6440, total step 721440, train lm loss: 0.8813509464263916
epoch 0, global step 6450, total step 721440, train lm loss: 0.9042973278090358
epoch 0, global step 6460, total step 721440, train lm loss: 0.8780724931508302
epoch 0, global step 6470, total step 721440, train lm loss: 0.9069722726941108
epoch 0, global step 6480, total step 721440, train lm loss: 0.9139575652778149
epoch 0, global step 6490, total step 721440, train lm loss: 0.8408140491694212
epoch 0, global step 6500, total step 721440, train lm loss: 0.8658696269616485
epoch 0, global step 6510, total step 721440, train lm loss: 0.8484312161803246
epoch 0, global step 6520, total step 721440, train lm loss: 0.8704706870019436
epoch 0, global step 6530, total step 721440, train lm loss: 0.8397863386198878
epoch 0, global step 6540, total step 721440, train lm loss: 0.8532091695815325
epoch 0, global step 6550, total step 721440, train lm loss: 0.8831786882132292
epoch 0, global step 6560, total step 721440, train lm loss: 0.9272437084466219
epoch 0, global step 6570, total step 721440, train lm loss: 0.9057500295341014
epoch 0, global step 6580, total step 721440, train lm loss: 0.9330632707104087
epoch 0, global step 6590, total step 721440, train lm loss: 0.8466069471091032
epoch 0, global step 6600, total step 721440, train lm loss: 0.8721637904644013
epoch 0, global step 6610, total step 721440, train lm loss: 0.8111514629796147
epoch 0, global step 6620, total step 721440, train lm loss: 0.8406634399667382
epoch 0, global step 6630, total step 721440, train lm loss: 0.8138355124741793
epoch 0, global step 6640, total step 721440, train lm loss: 0.8522938460111618
epoch 0, global step 6650, total step 721440, train lm loss: 0.8951224766671657
epoch 0, global step 6660, total step 721440, train lm loss: 0.96749188862741
epoch 0, global step 6670, total step 721440, train lm loss: 0.9470971118658781
epoch 0, global step 6680, total step 721440, train lm loss: 0.9057770740240813
epoch 0, global step 6690, total step 721440, train lm loss: 0.8559619350358844
epoch 0, global step 6700, total step 721440, train lm loss: 0.893608508259058
epoch 0, global step 6710, total step 721440, train lm loss: 0.9731580656021833
epoch 0, global step 6720, total step 721440, train lm loss: 0.8224312610924244
epoch 0, global step 6730, total step 721440, train lm loss: 0.9756700198166073
epoch 0, global step 6740, total step 721440, train lm loss: 0.9245385810732841
epoch 0, global step 6750, total step 721440, train lm loss: 0.9164944425225258
epoch 0, global step 6760, total step 721440, train lm loss: 0.8743713831529021
epoch 0, global step 6770, total step 721440, train lm loss: 0.8795144306495786
epoch 0, global step 6780, total step 721440, train lm loss: 0.8630741765722633
epoch 0, global step 6790, total step 721440, train lm loss: 0.837394081056118
epoch 0, global step 6800, total step 721440, train lm loss: 0.8641381312161684
epoch 0, global step 6810, total step 721440, train lm loss: 0.9104191603139042
epoch 0, global step 6820, total step 721440, train lm loss: 0.8507582545280457
epoch 0, global step 6830, total step 721440, train lm loss: 0.9089367564767599
epoch 0, global step 6840, total step 721440, train lm loss: 0.8360237505286932
epoch 0, global step 6850, total step 721440, train lm loss: 0.827421123161912
epoch 0, global step 6860, total step 721440, train lm loss: 0.8618443254381418
epoch 0, global step 6870, total step 721440, train lm loss: 0.8421533189713954
epoch 0, global step 6880, total step 721440, train lm loss: 0.8248048538342119
epoch 0, global step 6890, total step 721440, train lm loss: 0.8068795152008533
epoch 0, global step 6900, total step 721440, train lm loss: 0.9284892488270998
epoch 0, global step 6910, total step 721440, train lm loss: 0.8969473844394088
epoch 0, global step 6920, total step 721440, train lm loss: 0.8227209774777293
epoch 0, global step 6930, total step 721440, train lm loss: 0.8542953110300004
epoch 0, global step 6940, total step 721440, train lm loss: 0.8290227670222521
epoch 0, global step 6950, total step 721440, train lm loss: 0.7832227699458599
epoch 0, global step 6960, total step 721440, train lm loss: 0.8786403753794729
epoch 0, global step 6970, total step 721440, train lm loss: 0.9141764432191849
epoch 0, global step 6980, total step 721440, train lm loss: 0.7775853581726551
epoch 0, global step 6990, total step 721440, train lm loss: 0.8330624373629689
epoch 0, global step 7000, total step 721440, train lm loss: 0.8993836829438806
epoch 0, global step 7010, total step 721440, train lm loss: 0.8682517958804965
epoch 0, global step 7020, total step 721440, train lm loss: 0.8234573550522327
epoch 0, global step 7030, total step 721440, train lm loss: 0.9126067478209734
epoch 0, global step 7040, total step 721440, train lm loss: 0.8990846499800682
epoch 0, global step 7050, total step 721440, train lm loss: 0.8471667228266597
epoch 0, global step 7060, total step 721440, train lm loss: 0.8621122360229492
epoch 0, global step 7070, total step 721440, train lm loss: 0.8554106219671667
epoch 0, global step 7080, total step 721440, train lm loss: 0.7897900808602571
epoch 0, global step 7090, total step 721440, train lm loss: 0.7853177815675736
epoch 0, global step 7100, total step 721440, train lm loss: 0.9094050340354443
epoch 0, global step 7110, total step 721440, train lm loss: 0.9251932084560395
epoch 0, global step 7120, total step 721440, train lm loss: 0.8260272482410074
epoch 0, global step 7130, total step 721440, train lm loss: 0.8736982177942991
epoch 0, global step 7140, total step 721440, train lm loss: 0.8740087583661079
epoch 0, global step 7150, total step 721440, train lm loss: 0.9240019477903842
epoch 0, global step 7160, total step 721440, train lm loss: 0.8110963884741068
epoch 0, global step 7170, total step 721440, train lm loss: 0.8618595991283655
epoch 0, global step 7180, total step 721440, train lm loss: 0.8693426616489888
epoch 0, global step 7190, total step 721440, train lm loss: 0.8625492241233588
epoch 0, global step 7200, total step 721440, train lm loss: 0.9109098424203694
epoch 0, global step 7210, total step 721440, train lm loss: 0.8001769583672285
epoch 0, global step 7220, total step 721440, train lm loss: 0.8292816195636987
epoch 0, global step 7230, total step 721440, train lm loss: 0.8647327726706863
epoch 0, global step 7240, total step 721440, train lm loss: 0.8249362586066127
epoch 0, global step 7250, total step 721440, train lm loss: 0.8616184577345848
epoch 0, global step 7260, total step 721440, train lm loss: 0.8844871148467064
epoch 0, global step 7270, total step 721440, train lm loss: 0.8447170695289969
epoch 0, global step 7280, total step 721440, train lm loss: 0.8866751564666628
epoch 0, global step 7290, total step 721440, train lm loss: 0.9239210646599532
epoch 0, global step 7300, total step 721440, train lm loss: 0.8346062492579222
epoch 0, global step 7310, total step 721440, train lm loss: 0.8094783339649438
epoch 0, global step 7320, total step 721440, train lm loss: 0.8131561519578099
epoch 0, global step 7330, total step 721440, train lm loss: 0.8071581555530429
epoch 0, global step 7340, total step 721440, train lm loss: 0.8472194457426667
epoch 0, global step 7350, total step 721440, train lm loss: 0.7684412900358438
epoch 0, global step 7360, total step 721440, train lm loss: 0.8325619410723448
epoch 0, global step 7370, total step 721440, train lm loss: 0.9249450158327818
epoch 0, global step 7380, total step 721440, train lm loss: 0.810526954755187
epoch 0, global step 7390, total step 721440, train lm loss: 0.8205315170809626
epoch 0, global step 7400, total step 721440, train lm loss: 0.8514834468252956
epoch 0, global step 7410, total step 721440, train lm loss: 0.819158379547298
epoch 0, global step 7420, total step 721440, train lm loss: 0.8540124856866896
epoch 0, global step 7430, total step 721440, train lm loss: 0.841552596539259
epoch 0, global step 7440, total step 721440, train lm loss: 0.8280335374176502
epoch 0, global step 7450, total step 721440, train lm loss: 0.8350904803723097
epoch 0, global step 7460, total step 721440, train lm loss: 0.9171777915209531
epoch 0, global step 7470, total step 721440, train lm loss: 0.7756935326382518
epoch 0, global step 7480, total step 721440, train lm loss: 0.7716073725372553
epoch 0, global step 7490, total step 721440, train lm loss: 0.8846535086631775
epoch 0, global step 7500, total step 721440, train lm loss: 0.8015065416693687
epoch 0, global step 7510, total step 721440, train lm loss: 0.7881964007392526
epoch 0, global step 7520, total step 721440, train lm loss: 0.8643268732354045
epoch 0, global step 7530, total step 721440, train lm loss: 0.8729398753494024
epoch 0, global step 7540, total step 721440, train lm loss: 0.8908234404399991
epoch 0, global step 7550, total step 721440, train lm loss: 0.8760856170207262
epoch 0, global step 7560, total step 721440, train lm loss: 0.7740526836365461
epoch 0, global step 7570, total step 721440, train lm loss: 0.8173505257815122
epoch 0, global step 7580, total step 721440, train lm loss: 0.8766816401854157
epoch 0, global step 7590, total step 721440, train lm loss: 0.8345618721097707
epoch 0, global step 7600, total step 721440, train lm loss: 0.8531207447871566
epoch 0, global step 7610, total step 721440, train lm loss: 0.7591610083356499
epoch 0, global step 7620, total step 721440, train lm loss: 0.7907246815040707
epoch 0, global step 7630, total step 721440, train lm loss: 0.8062082033604383
epoch 0, global step 7640, total step 721440, train lm loss: 0.7834298871457577
epoch 0, global step 7650, total step 721440, train lm loss: 0.7948307877406477
epoch 0, global step 7660, total step 721440, train lm loss: 0.7845712838694453
epoch 0, global step 7670, total step 721440, train lm loss: 0.783243734203279
epoch 0, global step 7680, total step 721440, train lm loss: 0.8327578189782798
epoch 0, global step 7690, total step 721440, train lm loss: 0.8416165748611093
epoch 0, global step 7700, total step 721440, train lm loss: 0.79317716229707
epoch 0, global step 7710, total step 721440, train lm loss: 0.8355638980865479
epoch 0, global step 7720, total step 721440, train lm loss: 0.8563342882320285
epoch 0, global step 7730, total step 721440, train lm loss: 0.8197771884500981
epoch 0, global step 7740, total step 721440, train lm loss: 0.8542116288095712
epoch 0, global step 7750, total step 721440, train lm loss: 0.7338701149448752
epoch 0, global step 7760, total step 721440, train lm loss: 0.8272176189348102
epoch 0, global step 7770, total step 721440, train lm loss: 0.8632141340523958
epoch 0, global step 7780, total step 721440, train lm loss: 0.790753360837698
epoch 0, global step 7790, total step 721440, train lm loss: 0.8355503799393773
epoch 0, global step 7800, total step 721440, train lm loss: 0.8188591225072741
epoch 0, global step 7810, total step 721440, train lm loss: 0.7138046951964497
epoch 0, global step 7820, total step 721440, train lm loss: 0.7662431282922626
epoch 0, global step 7830, total step 721440, train lm loss: 0.9150040686130524
epoch 0, global step 7840, total step 721440, train lm loss: 0.7681203396059573
epoch 0, global step 7850, total step 721440, train lm loss: 0.8449815401807428
epoch 0, global step 7860, total step 721440, train lm loss: 0.7575035706162453
epoch 0, global step 7870, total step 721440, train lm loss: 0.9078806530684232
epoch 0, global step 7880, total step 721440, train lm loss: 0.8605771165341138
epoch 0, global step 7890, total step 721440, train lm loss: 0.8877821270376444
epoch 0, global step 7900, total step 721440, train lm loss: 0.7817071934230626
epoch 0, global step 7910, total step 721440, train lm loss: 0.8192316507920623
epoch 0, global step 7920, total step 721440, train lm loss: 0.7616098491474986
epoch 0, global step 7930, total step 721440, train lm loss: 0.8340856164693833
epoch 0, global step 7940, total step 721440, train lm loss: 0.7997579956427217
epoch 0, global step 7950, total step 721440, train lm loss: 0.7748158864676953
epoch 0, global step 7960, total step 721440, train lm loss: 0.7557173883542418
epoch 0, global step 7970, total step 721440, train lm loss: 0.8186821153387427
epoch 0, global step 7980, total step 721440, train lm loss: 0.7877772331237793
epoch 0, global step 7990, total step 721440, train lm loss: 0.8092082289978861
epoch 0, global step 8000, total step 721440, train lm loss: 0.8581349741667509
epoch 0, global step 8010, total step 721440, train lm loss: 0.8206423733383417
epoch 0, global step 8020, total step 721440, train lm loss: 0.8615438922308385
epoch 0, global step 8030, total step 721440, train lm loss: 0.8192897204309701
epoch 0, global step 8040, total step 721440, train lm loss: 0.8198587828315794
epoch 0, global step 8050, total step 721440, train lm loss: 0.7822840314358472
epoch 0, global step 8060, total step 721440, train lm loss: 0.8878045212477446
epoch 0, global step 8070, total step 721440, train lm loss: 0.8349655114114285
epoch 0, global step 8080, total step 721440, train lm loss: 0.7794631561264396
epoch 0, global step 8090, total step 721440, train lm loss: 0.8201894914731384
epoch 0, global step 8100, total step 721440, train lm loss: 0.8310915298759938
epoch 0, global step 8110, total step 721440, train lm loss: 0.8403123410418629
epoch 0, global step 8120, total step 721440, train lm loss: 0.7851336795836688
epoch 0, global step 8130, total step 721440, train lm loss: 0.8354728711768985
epoch 0, global step 8140, total step 721440, train lm loss: 0.7483309539034962
epoch 0, global step 8150, total step 721440, train lm loss: 0.885139293782413
epoch 0, global step 8160, total step 721440, train lm loss: 0.7701535150408745
epoch 0, global step 8170, total step 721440, train lm loss: 0.8105007415637374
epoch 0, global step 8180, total step 721440, train lm loss: 0.7739550292491912
epoch 0, global step 8190, total step 721440, train lm loss: 0.7880523011088372
epoch 0, global step 8200, total step 721440, train lm loss: 0.7809377459809184
epoch 0, global step 8210, total step 721440, train lm loss: 0.7131523013114929
epoch 0, global step 8220, total step 721440, train lm loss: 0.8741880398243665
epoch 0, global step 8230, total step 721440, train lm loss: 0.8165998352691531
epoch 0, global step 8240, total step 721440, train lm loss: 0.7806616954505443
epoch 0, global step 8250, total step 721440, train lm loss: 0.8424012117087841
epoch 0, global step 8260, total step 721440, train lm loss: 0.7614744925871492
epoch 0, global step 8270, total step 721440, train lm loss: 0.7676738673821092
epoch 0, global step 8280, total step 721440, train lm loss: 0.8113332003355026
epoch 0, global step 8290, total step 721440, train lm loss: 0.8466874119825661
epoch 0, global step 8300, total step 721440, train lm loss: 0.8624244391918182
epoch 0, global step 8310, total step 721440, train lm loss: 0.8041535432450473
epoch 0, global step 8320, total step 721440, train lm loss: 0.8333208313211798
epoch 0, global step 8330, total step 721440, train lm loss: 0.8308622965589165
epoch 0, global step 8340, total step 721440, train lm loss: 0.8097668282687664
epoch 0, global step 8350, total step 721440, train lm loss: 0.8075198832899332
epoch 0, global step 8360, total step 721440, train lm loss: 0.8303123949095607
epoch 0, global step 8370, total step 721440, train lm loss: 0.7888075340539217
epoch 0, global step 8380, total step 721440, train lm loss: 0.8010461598634719
epoch 0, global step 8390, total step 721440, train lm loss: 0.8326339641585946
epoch 0, global step 8400, total step 721440, train lm loss: 0.857146431133151
epoch 0, global step 8410, total step 721440, train lm loss: 0.7847964135929942
epoch 0, global step 8420, total step 721440, train lm loss: 0.7924297677353025
epoch 0, global step 8430, total step 721440, train lm loss: 0.8070461332798005
epoch 0, global step 8440, total step 721440, train lm loss: 0.7670185197144747
epoch 0, global step 8450, total step 721440, train lm loss: 0.8007036253809929
epoch 0, global step 8460, total step 721440, train lm loss: 0.7432329540140927
epoch 0, global step 8470, total step 721440, train lm loss: 0.7939703669399023
epoch 0, global step 8480, total step 721440, train lm loss: 0.7550346693955362
epoch 0, global step 8490, total step 721440, train lm loss: 0.8019677395932376
epoch 0, global step 8500, total step 721440, train lm loss: 0.779675067961216
epoch 0, global step 8510, total step 721440, train lm loss: 0.8902952637523412
epoch 0, global step 8520, total step 721440, train lm loss: 0.8297690561041235
epoch 0, global step 8530, total step 721440, train lm loss: 0.7580001465976238
epoch 0, global step 8540, total step 721440, train lm loss: 0.7732739049941302
epoch 0, global step 8550, total step 721440, train lm loss: 0.7088735327124596
epoch 0, global step 8560, total step 721440, train lm loss: 0.7246418715454638
epoch 0, global step 8570, total step 721440, train lm loss: 0.826781003549695
epoch 0, global step 8580, total step 721440, train lm loss: 0.8448196100071073
epoch 0, global step 8590, total step 721440, train lm loss: 0.8549374992027878
epoch 0, global step 8600, total step 721440, train lm loss: 0.8326518386602402
epoch 0, global step 8610, total step 721440, train lm loss: 0.7356200207024812
epoch 0, global step 8620, total step 721440, train lm loss: 0.9131393095478415
epoch 0, global step 8630, total step 721440, train lm loss: 0.7921988341957331
epoch 0, global step 8640, total step 721440, train lm loss: 0.8196013323962689
epoch 0, global step 8650, total step 721440, train lm loss: 0.7363438710570336
epoch 0, global step 8660, total step 721440, train lm loss: 0.7657214349135757
epoch 0, global step 8670, total step 721440, train lm loss: 0.7593170134350657
epoch 0, global step 8680, total step 721440, train lm loss: 0.806375491246581
epoch 0, global step 8690, total step 721440, train lm loss: 0.8217458481900394
epoch 0, global step 8700, total step 721440, train lm loss: 0.8344325307756663
epoch 0, global step 8710, total step 721440, train lm loss: 0.7693850984796882
epoch 0, global step 8720, total step 721440, train lm loss: 0.7769253142178059
epoch 0, global step 8730, total step 721440, train lm loss: 0.8461439073085785
epoch 0, global step 8740, total step 721440, train lm loss: 0.8149794535711408
epoch 0, global step 8750, total step 721440, train lm loss: 0.7744393926113844
epoch 0, global step 8760, total step 721440, train lm loss: 0.7298318423330784
epoch 0, global step 8770, total step 721440, train lm loss: 0.8208982568234205
epoch 0, global step 8780, total step 721440, train lm loss: 0.7721977746114135
epoch 0, global step 8790, total step 721440, train lm loss: 0.7883065616711974
epoch 0, global step 8800, total step 721440, train lm loss: 0.7048936987295746
epoch 0, global step 8810, total step 721440, train lm loss: 0.7547462755814195
epoch 0, global step 8820, total step 721440, train lm loss: 0.7448528304696083
epoch 0, global step 8830, total step 721440, train lm loss: 0.7965146645903587
epoch 0, global step 8840, total step 721440, train lm loss: 0.7297757856547833
epoch 0, global step 8850, total step 721440, train lm loss: 0.7861037287861109
epoch 0, global step 8860, total step 721440, train lm loss: 0.7873520016670227
epoch 0, global step 8870, total step 721440, train lm loss: 0.7819141966290772
epoch 0, global step 8880, total step 721440, train lm loss: 0.7566674552857876
epoch 0, global step 8890, total step 721440, train lm loss: 0.7461221750825644
epoch 0, global step 8900, total step 721440, train lm loss: 0.815945421718061
epoch 0, global step 8910, total step 721440, train lm loss: 0.8258000615984201
epoch 0, global step 8920, total step 721440, train lm loss: 0.8486665852367878
epoch 0, global step 8930, total step 721440, train lm loss: 0.8308635011315346
epoch 0, global step 8940, total step 721440, train lm loss: 0.7702901544049382
epoch 0, global step 8950, total step 721440, train lm loss: 0.7548473539762199
epoch 0, global step 8960, total step 721440, train lm loss: 0.8234494930133224
epoch 0, global step 8970, total step 721440, train lm loss: 0.6800799109041691
epoch 0, global step 8980, total step 721440, train lm loss: 0.812704305909574
epoch 0, global step 8990, total step 721440, train lm loss: 0.718292910978198
epoch 0, global step 9000, total step 721440, train lm loss: 0.7287820725701749
epoch 0, global step 9010, total step 721440, train lm loss: 0.9044614335522055
epoch 1, global step 9020, total step 721440, train lm loss: 0.807206092402339
epoch 1, global step 9030, total step 721440, train lm loss: 0.968298413977027
epoch 1, global step 9040, total step 721440, train lm loss: 0.9906848071143031
epoch 1, global step 9050, total step 721440, train lm loss: 0.9624267313629389
epoch 1, global step 9060, total step 721440, train lm loss: 0.8895362198352814
epoch 1, global step 9070, total step 721440, train lm loss: 0.9778053864836693
epoch 1, global step 9080, total step 721440, train lm loss: 0.9304776169359684
epoch 1, global step 9090, total step 721440, train lm loss: 0.81196003947407
epoch 1, global step 9100, total step 721440, train lm loss: 0.893759517557919
epoch 1, global step 9110, total step 721440, train lm loss: 0.9105395104736089
epoch 1, global step 9120, total step 721440, train lm loss: 0.8776223108172416
epoch 1, global step 9130, total step 721440, train lm loss: 0.9051630720496178
epoch 1, global step 9140, total step 721440, train lm loss: 0.9399677485227584
epoch 1, global step 9150, total step 721440, train lm loss: 0.924089203029871
epoch 1, global step 9160, total step 721440, train lm loss: 0.8423876663669944
epoch 1, global step 9170, total step 721440, train lm loss: 0.9559244100004435
epoch 1, global step 9180, total step 721440, train lm loss: 0.9326311856508255
epoch 1, global step 9190, total step 721440, train lm loss: 0.9067472670227289
epoch 1, global step 9200, total step 721440, train lm loss: 0.8096766553819179
epoch 1, global step 9210, total step 721440, train lm loss: 0.9507454471662641
epoch 1, global step 9220, total step 721440, train lm loss: 0.8582447668537497
epoch 1, global step 9230, total step 721440, train lm loss: 0.9643061041831971
epoch 1, global step 9240, total step 721440, train lm loss: 0.9495822919532657
epoch 1, global step 9250, total step 721440, train lm loss: 0.9197757747024298
epoch 1, global step 9260, total step 721440, train lm loss: 0.8545135047286749
epoch 1, global step 9270, total step 721440, train lm loss: 0.8624893363565207
epoch 1, global step 9280, total step 721440, train lm loss: 0.8439648035913706
epoch 1, global step 9290, total step 721440, train lm loss: 0.9579183235764503
epoch 1, global step 9300, total step 721440, train lm loss: 0.8521873770281673
epoch 1, global step 9310, total step 721440, train lm loss: 0.8958911146968603
epoch 1, global step 9320, total step 721440, train lm loss: 0.9202270509675146
epoch 1, global step 9330, total step 721440, train lm loss: 0.8538630824536085
epoch 1, global step 9340, total step 721440, train lm loss: 0.8690433237701655
epoch 1, global step 9350, total step 721440, train lm loss: 0.8673563469201326
epoch 1, global step 9360, total step 721440, train lm loss: 0.81705765388906
epoch 1, global step 9370, total step 721440, train lm loss: 0.8592451842501759
epoch 1, global step 9380, total step 721440, train lm loss: 0.8233919583261013
epoch 1, global step 9390, total step 721440, train lm loss: 0.8566052293404937
epoch 1, global step 9400, total step 721440, train lm loss: 0.795978806912899
epoch 1, global step 9410, total step 721440, train lm loss: 0.8311417583376169
epoch 1, global step 9420, total step 721440, train lm loss: 0.8834671346470714
epoch 1, global step 9430, total step 721440, train lm loss: 0.8120660208165645
epoch 1, global step 9440, total step 721440, train lm loss: 0.8177301747724414
epoch 1, global step 9450, total step 721440, train lm loss: 0.8813744354993105
epoch 1, global step 9460, total step 721440, train lm loss: 0.8276197351515293
epoch 1, global step 9470, total step 721440, train lm loss: 0.8173259230330586
epoch 1, global step 9480, total step 721440, train lm loss: 0.8419286612421274
epoch 1, global step 9490, total step 721440, train lm loss: 0.8079643259756267
epoch 1, global step 9500, total step 721440, train lm loss: 0.8129696046933532
epoch 1, global step 9510, total step 721440, train lm loss: 0.9189002847298979
epoch 1, global step 9520, total step 721440, train lm loss: 0.8630417302250862
epoch 1, global step 9530, total step 721440, train lm loss: 0.8711139160208404
epoch 1, global step 9540, total step 721440, train lm loss: 0.7583937264978886
epoch 1, global step 9550, total step 721440, train lm loss: 0.914395859465003
epoch 1, global step 9560, total step 721440, train lm loss: 0.8652595655061305
epoch 1, global step 9570, total step 721440, train lm loss: 0.7876354152336716
epoch 1, global step 9580, total step 721440, train lm loss: 0.8241922890767455
epoch 1, global step 9590, total step 721440, train lm loss: 0.856346208229661
epoch 1, global step 9600, total step 721440, train lm loss: 0.8219169555231929
epoch 1, global step 9610, total step 721440, train lm loss: 0.9134164480492473
epoch 1, global step 9620, total step 721440, train lm loss: 0.885120252892375
epoch 1, global step 9630, total step 721440, train lm loss: 0.8493360567837953
epoch 1, global step 9640, total step 721440, train lm loss: 0.8917773006483912
epoch 1, global step 9650, total step 721440, train lm loss: 0.8121438894420863
epoch 1, global step 9660, total step 721440, train lm loss: 0.8385462106205523
epoch 1, global step 9670, total step 721440, train lm loss: 0.7925158619880677
epoch 1, global step 9680, total step 721440, train lm loss: 0.9100490922108293
epoch 1, global step 9690, total step 721440, train lm loss: 0.8694995807483792
epoch 1, global step 9700, total step 721440, train lm loss: 0.8012454148381949
epoch 1, global step 9710, total step 721440, train lm loss: 0.9042544074356555
epoch 1, global step 9720, total step 721440, train lm loss: 0.8337791932746768
epoch 1, global step 9730, total step 721440, train lm loss: 0.8117761727422476
epoch 1, global step 9740, total step 721440, train lm loss: 0.837096494436264
epoch 1, global step 9750, total step 721440, train lm loss: 0.8424850642681122
epoch 1, global step 9760, total step 721440, train lm loss: 0.9153663327917456
epoch 1, global step 9770, total step 721440, train lm loss: 0.8780827157199382
epoch 1, global step 9780, total step 721440, train lm loss: 0.8372082689777016
epoch 1, global step 9790, total step 721440, train lm loss: 0.7681792741641402
epoch 1, global step 9800, total step 721440, train lm loss: 0.8858794163912534
epoch 1, global step 9810, total step 721440, train lm loss: 0.8119352631270885
epoch 1, global step 9820, total step 721440, train lm loss: 0.8974411657080055
epoch 1, global step 9830, total step 721440, train lm loss: 0.8789455637335777
epoch 1, global step 9840, total step 721440, train lm loss: 0.8405075900256633
epoch 1, global step 9850, total step 721440, train lm loss: 0.8321519117802382
epoch 1, global step 9860, total step 721440, train lm loss: 0.8282253114506603
epoch 1, global step 9870, total step 721440, train lm loss: 0.8477278120815754
epoch 1, global step 9880, total step 721440, train lm loss: 0.7860935011878609
epoch 1, global step 9890, total step 721440, train lm loss: 0.848341615870595
epoch 1, global step 9900, total step 721440, train lm loss: 0.8393785729072988
epoch 1, global step 9910, total step 721440, train lm loss: 0.7549745721742511
epoch 1, global step 9920, total step 721440, train lm loss: 0.8397021509706974
epoch 1, global step 9930, total step 721440, train lm loss: 0.8262385670095682
epoch 1, global step 9940, total step 721440, train lm loss: 0.8512586344033479
epoch 1, global step 9950, total step 721440, train lm loss: 0.8415364602580666
epoch 1, global step 9960, total step 721440, train lm loss: 0.8278720597736537
epoch 1, global step 9970, total step 721440, train lm loss: 0.7850371255539358
epoch 1, global step 9980, total step 721440, train lm loss: 0.8512617545202374
epoch 1, global step 9990, total step 721440, train lm loss: 0.9075105661526323
epoch 1, global step 10000, total step 721440, train lm loss: 0.9091619875282049
epoch 1, global step 10010, total step 721440, train lm loss: 0.7571666270494462
epoch 1, global step 10020, total step 721440, train lm loss: 0.7643200406804681
epoch 1, global step 10030, total step 721440, train lm loss: 0.7123141031712293
epoch 1, global step 10040, total step 721440, train lm loss: 0.7296007629483938
epoch 1, global step 10050, total step 721440, train lm loss: 0.8080252847634256
epoch 1, global step 10060, total step 721440, train lm loss: 0.7759619757533074
epoch 1, global step 10070, total step 721440, train lm loss: 0.7678855530917644
epoch 1, global step 10080, total step 721440, train lm loss: 0.6789213109761476
epoch 1, global step 10090, total step 721440, train lm loss: 0.7428981414064765
epoch 1, global step 10100, total step 721440, train lm loss: 0.7739670976996422
epoch 1, global step 10110, total step 721440, train lm loss: 0.7300696603953838
epoch 1, global step 10120, total step 721440, train lm loss: 0.7029076770879328
epoch 1, global step 10130, total step 721440, train lm loss: 0.7203993111848831
epoch 1, global step 10140, total step 721440, train lm loss: 0.8531659523025155
epoch 1, global step 10150, total step 721440, train lm loss: 0.7519222149625421
epoch 1, global step 10160, total step 721440, train lm loss: 0.7258157656528056
epoch 1, global step 10170, total step 721440, train lm loss: 0.7239841583184898
epoch 1, global step 10180, total step 721440, train lm loss: 0.7282964201644063
epoch 1, global step 10190, total step 721440, train lm loss: 0.7258724806830287
epoch 1, global step 10200, total step 721440, train lm loss: 0.7521496246568858
epoch 1, global step 10210, total step 721440, train lm loss: 0.7340118562802672
epoch 1, global step 10220, total step 721440, train lm loss: 0.6994140623137355
epoch 1, global step 10230, total step 721440, train lm loss: 0.731693541072309
epoch 1, global step 10240, total step 721440, train lm loss: 0.7720413235016167
epoch 1, global step 10250, total step 721440, train lm loss: 0.7925314638763666
epoch 1, global step 10260, total step 721440, train lm loss: 0.7662630253471434
epoch 1, global step 10270, total step 721440, train lm loss: 0.7911130417138338
epoch 1, global step 10280, total step 721440, train lm loss: 0.7293563449755311
epoch 1, global step 10290, total step 721440, train lm loss: 0.7055189428851009
epoch 1, global step 10300, total step 721440, train lm loss: 0.8320607184432447
epoch 1, global step 10310, total step 721440, train lm loss: 0.7587488800287246
epoch 1, global step 10320, total step 721440, train lm loss: 0.8168464217334985
epoch 1, global step 10330, total step 721440, train lm loss: 0.7276374633423984
epoch 1, global step 10340, total step 721440, train lm loss: 0.7977040342986583
epoch 1, global step 10350, total step 721440, train lm loss: 0.7448474632576108
epoch 1, global step 10360, total step 721440, train lm loss: 0.7139911895617843
epoch 1, global step 10370, total step 721440, train lm loss: 0.6341786000877618
epoch 1, global step 10380, total step 721440, train lm loss: 0.7016357678920031
epoch 1, global step 10390, total step 721440, train lm loss: 0.6885417234152555
epoch 1, global step 10400, total step 721440, train lm loss: 0.7885647624731064
epoch 1, global step 10410, total step 721440, train lm loss: 0.7336639096960426
epoch 1, global step 10420, total step 721440, train lm loss: 0.7611021414399147
epoch 1, global step 10430, total step 721440, train lm loss: 0.6966028301976621
epoch 1, global step 10440, total step 721440, train lm loss: 0.7263525689020753
epoch 1, global step 10450, total step 721440, train lm loss: 0.7882170365191996
epoch 1, global step 10460, total step 721440, train lm loss: 0.6759286998771131
epoch 1, global step 10470, total step 721440, train lm loss: 0.701197168044746
epoch 1, global step 10480, total step 721440, train lm loss: 0.7864371344447136
epoch 1, global step 10490, total step 721440, train lm loss: 0.7736655319109559
epoch 1, global step 10500, total step 721440, train lm loss: 0.7095727798528969
epoch 1, global step 10510, total step 721440, train lm loss: 0.784606965072453
epoch 1, global step 10520, total step 721440, train lm loss: 0.6526239203289151
epoch 1, global step 10530, total step 721440, train lm loss: 0.7143014447763563
epoch 1, global step 10540, total step 721440, train lm loss: 0.7602340076118708
epoch 1, global step 10550, total step 721440, train lm loss: 0.777990385144949
epoch 1, global step 10560, total step 721440, train lm loss: 0.6977354029193521
epoch 1, global step 10570, total step 721440, train lm loss: 0.7432721208781004
epoch 1, global step 10580, total step 721440, train lm loss: 0.8035595481283963
epoch 1, global step 10590, total step 721440, train lm loss: 0.7884171230718493
epoch 1, global step 10600, total step 721440, train lm loss: 0.7071529204025865
epoch 1, global step 10610, total step 721440, train lm loss: 0.7230988430790604
epoch 1, global step 10620, total step 721440, train lm loss: 0.6573458995670081
epoch 1, global step 10630, total step 721440, train lm loss: 0.6772206380963326
epoch 1, global step 10640, total step 721440, train lm loss: 0.7179603144526482
epoch 1, global step 10650, total step 721440, train lm loss: 0.7602131282910705
epoch 1, global step 10660, total step 721440, train lm loss: 0.7556463368237019
epoch 1, global step 10670, total step 721440, train lm loss: 0.7389684647321701
epoch 1, global step 10680, total step 721440, train lm loss: 0.6998178627341985
epoch 1, global step 10690, total step 721440, train lm loss: 0.7568565294146538
epoch 1, global step 10700, total step 721440, train lm loss: 0.7437970176339149
epoch 1, global step 10710, total step 721440, train lm loss: 0.7348074540495872
epoch 1, global step 10720, total step 721440, train lm loss: 0.7877279281616211
epoch 1, global step 10730, total step 721440, train lm loss: 0.7158616254106164
epoch 1, global step 10740, total step 721440, train lm loss: 0.7859851446002721
epoch 1, global step 10750, total step 721440, train lm loss: 0.7058597289957106
epoch 1, global step 10760, total step 721440, train lm loss: 0.6983837279491126
epoch 1, global step 10770, total step 721440, train lm loss: 0.7697025194764138
epoch 1, global step 10780, total step 721440, train lm loss: 0.6857766732573509
epoch 1, global step 10790, total step 721440, train lm loss: 0.7276969715952873
epoch 1, global step 10800, total step 721440, train lm loss: 0.7550693763419986
epoch 1, global step 10810, total step 721440, train lm loss: 0.7049291400238872
epoch 1, global step 10820, total step 721440, train lm loss: 0.742093201354146
epoch 1, global step 10830, total step 721440, train lm loss: 0.7285455983132124
epoch 1, global step 10840, total step 721440, train lm loss: 0.732998026534915
epoch 1, global step 10850, total step 721440, train lm loss: 0.6853284791111947
epoch 1, global step 10860, total step 721440, train lm loss: 0.7940926128067076
epoch 1, global step 10870, total step 721440, train lm loss: 0.6503151969984173
epoch 1, global step 10880, total step 721440, train lm loss: 0.6774383075535297
epoch 1, global step 10890, total step 721440, train lm loss: 0.7406081001274287
epoch 1, global step 10900, total step 721440, train lm loss: 0.7018158211372792
epoch 1, global step 10910, total step 721440, train lm loss: 0.6937701100483536
epoch 1, global step 10920, total step 721440, train lm loss: 0.718199216760695
epoch 1, global step 10930, total step 721440, train lm loss: 0.6745331699028612
epoch 1, global step 10940, total step 721440, train lm loss: 0.7719356246292591
epoch 1, global step 10950, total step 721440, train lm loss: 0.6721514333970845
epoch 1, global step 10960, total step 721440, train lm loss: 0.6853592917323112
epoch 1, global step 10970, total step 721440, train lm loss: 0.6393851811997593
epoch 1, global step 10980, total step 721440, train lm loss: 0.635495300963521
epoch 1, global step 10990, total step 721440, train lm loss: 0.7313652691431344
epoch 1, global step 11000, total step 721440, train lm loss: 0.7397665500640869
epoch 1, global step 11010, total step 721440, train lm loss: 0.6696331726387144
epoch 1, global step 11020, total step 721440, train lm loss: 0.6528981529176235
epoch 1, global step 11030, total step 721440, train lm loss: 0.7500056646298617
epoch 1, global step 11040, total step 721440, train lm loss: 0.711378139257431
epoch 1, global step 11050, total step 721440, train lm loss: 0.7088560328353196
epoch 1, global step 11060, total step 721440, train lm loss: 0.6828183337114752
epoch 1, global step 11070, total step 721440, train lm loss: 0.6691882838495076
epoch 1, global step 11080, total step 721440, train lm loss: 0.7469778787344694
epoch 1, global step 11090, total step 721440, train lm loss: 0.7213219432160258
epoch 1, global step 11100, total step 721440, train lm loss: 0.7225772376172245
epoch 1, global step 11110, total step 721440, train lm loss: 0.745939907990396
epoch 1, global step 11120, total step 721440, train lm loss: 0.7357204224914312
epoch 1, global step 11130, total step 721440, train lm loss: 0.6667236397508531
epoch 1, global step 11140, total step 721440, train lm loss: 0.8160131370648742
epoch 1, global step 11150, total step 721440, train lm loss: 0.727260029874742
epoch 1, global step 11160, total step 721440, train lm loss: 0.7226683720946312
epoch 1, global step 11170, total step 721440, train lm loss: 0.736163545679301
epoch 1, global step 11180, total step 721440, train lm loss: 0.7351747276261449
epoch 1, global step 11190, total step 721440, train lm loss: 0.7474655931815505
epoch 1, global step 11200, total step 721440, train lm loss: 0.7022776925005019
epoch 1, global step 11210, total step 721440, train lm loss: 0.7774149958044291
